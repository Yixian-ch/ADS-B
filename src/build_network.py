import os
import argparse
import numpy as np
import pandas as pd
import matplotlib
matplotlib.use('Agg')
import matplotlib.pyplot as plt
import random
import logging

import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.utils.data import DataLoader, TensorDataset, Subset
from sklearn.manifold import TSNE
import seaborn as sns
from sklearn.metrics import confusion_matrix


# é…ç½®æ—¥å¿—è®°å½•
def setup_logger(save_dir):
    """è®¾ç½®æ—¥å¿—è®°å½•å™¨"""
    log_file = os.path.join(save_dir, 'training.log')
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(levelname)s - %(message)s',
        handlers=[
            logging.FileHandler(log_file),
            logging.StreamHandler()
        ]
    )
    return logging.getLogger(__name__)

# è®¾ç½®éšæœºç§å­ï¼Œç¡®ä¿ç»“æœå¯å¤ç°
def set_seed(seed=42):
    np.random.seed(seed)
    random.seed(seed)
    torch.manual_seed(seed)
    if torch.cuda.is_available():
        torch.cuda.manual_seed(seed)
        torch.cuda.manual_seed_all(seed)
    torch.backends.cudnn.deterministic = True
    torch.backends.cudnn.benchmark = False

# è®¾ç½®éšæœºç§å­
set_seed(42)

def load_and_preprocess_grouped_data(data_path, test_size=0.2, val_size=0.1):
    """
    åŠ è½½å’Œé¢„å¤„ç†åˆ†ç»„é™ç»´åçš„æ•°æ®
    é€‚é…æ–°çš„CSVæ ¼å¼ï¼šç¬æ€ç‰¹å¾ + ç¨³æ€ç‰¹å¾ + target + individual_id + route
    """
    print(f"åŠ è½½åˆ†ç»„æ•°æ®: {data_path}")
    df = pd.read_csv(data_path)
    
    print(f"åŸå§‹æ•°æ®å½¢çŠ¶: {df.shape}")
    print(f"æ•°æ®åˆ—å: {list(df.columns)}")
    
    # åˆ†ç¦»ç¬æ€å’Œç¨³æ€ç‰¹å¾
    transient_cols = [f'transient_component_{i}' for i in range(1, 16)]  # 15ä¸ªç¬æ€ç‰¹å¾
    steady_cols = [f'steady_component_{i}' for i in range(1, 16)]        # 15ä¸ªç¨³æ€ç‰¹å¾
    
    # æ£€æŸ¥æ‰€æœ‰ç‰¹å¾åˆ—æ˜¯å¦å­˜åœ¨
    missing_cols = []
    for col in transient_cols + steady_cols:
        if col not in df.columns:
            missing_cols.append(col)
    
    if missing_cols:
        print(f"âŒ ç¼ºå°‘ç‰¹å¾åˆ—: {missing_cols}")
        return None, None, None, None
    
    # æå–ç‰¹å¾å’Œæ ‡ç­¾
    X_transient = df[transient_cols].values.astype(np.float32)
    X_steady = df[steady_cols].values.astype(np.float32)
    
    # å¤„ç†æ ‡ç­¾ - å°†targetè½¬æ¢ä¸ºä»0å¼€å§‹çš„è¿ç»­æ•´æ•°
    unique_targets = sorted(df['target'].unique())
    target_mapping = {target: idx for idx, target in enumerate(unique_targets)}
    y = df['target'].map(target_mapping).values.astype(np.int64)
    
    print(f"ç¬æ€ç‰¹å¾ç»´åº¦: {X_transient.shape}")
    print(f"ç¨³æ€ç‰¹å¾ç»´åº¦: {X_steady.shape}")
    print(f"æ ‡ç­¾ç»´åº¦: {y.shape}")
    print(f"ç±»åˆ«æ•°é‡: {len(unique_targets)}")
    print(f"æ ‡ç­¾èŒƒå›´: {y.min()} - {y.max()}")
    
    # åˆå¹¶ç¬æ€å’Œç¨³æ€ç‰¹å¾ä¸ºå•ä¸€ç‰¹å¾çŸ©é˜µ
    X = np.concatenate([X_transient, X_steady], axis=1)  # 30ç»´ç‰¹å¾
    
    print(f"åˆå¹¶åç‰¹å¾ç»´åº¦: {X.shape}")
    
    # æ ‡å‡†åŒ–ç‰¹å¾
    from sklearn.preprocessing import StandardScaler
    scaler = StandardScaler()
    X = scaler.fit_transform(X)
    
    # åˆ†å‰²æ•°æ®é›†
    from sklearn.model_selection import train_test_split
    
    # é¦–å…ˆåˆ†å‰²å‡ºæµ‹è¯•é›†
    X_temp, X_test, y_temp, y_test = train_test_split(
        X, y, test_size=test_size, random_state=42, stratify=y
    )
    
    # ä»å‰©ä½™æ•°æ®ä¸­åˆ†å‰²å‡ºéªŒè¯é›†
    val_ratio = val_size / (1 - test_size)
    X_train, X_val, y_train, y_val = train_test_split(
        X_temp, y_temp, test_size=val_ratio, random_state=42, stratify=y_temp
    )
    
    print(f"æ•°æ®åˆ†å‰²å®Œæˆ. è®­ç»ƒé›†: {len(y_train)}, éªŒè¯é›†: {len(y_val)}, æµ‹è¯•é›†: {len(y_test)}")
    
    # åˆ›å»ºå¼ é‡æ•°æ®é›†
    train_dataset = TensorDataset(
        torch.FloatTensor(X_train),
        torch.LongTensor(y_train)
    )
    
    val_dataset = TensorDataset(
        torch.FloatTensor(X_val),
        torch.LongTensor(y_val)
    )
    
    test_dataset = TensorDataset(
        torch.FloatTensor(X_test),
        torch.LongTensor(y_test)
    )
    
    return train_dataset, val_dataset, test_dataset, len(unique_targets), target_mapping, scaler

# è‡ªæ³¨æ„åŠ›æ¨¡å—ï¼Œç”¨äºç‰¹å¾å†…éƒ¨çš„å…³ç³»å»ºæ¨¡
class SelfAttention(nn.Module):
    """
    è‡ªæ³¨æ„åŠ›æ¨¡å—ï¼Œç”¨äºç‰¹å¾å†…éƒ¨çš„å…³ç³»å»ºæ¨¡
    """
    def __init__(self, embed_size, heads=1):
        super(SelfAttention, self).__init__()
        self.embed_size = embed_size
        self.heads = heads
        self.head_dim = embed_size // heads
        
        assert (self.head_dim * heads == embed_size), "Embed size needs to be divisible by heads"
        
        self.query = nn.Linear(embed_size, embed_size)
        self.key = nn.Linear(embed_size, embed_size)
        self.value = nn.Linear(embed_size, embed_size)
        self.fc_out = nn.Linear(embed_size, embed_size)
        self.scale = self.head_dim ** 0.5
        
    def forward(self, x):
        # x: [batch_size, embed_size]
        batch_size = x.shape[0]
        
        # å°†è¾“å…¥è½¬æ¢ä¸ºé€‚åˆæ³¨æ„åŠ›æœºåˆ¶çš„å½¢çŠ¶
        x_reshaped = x.unsqueeze(1)  # [batch_size, 1, embed_size]
        
        # å°†è¾“å…¥é€šè¿‡çº¿æ€§å±‚å¹¶åˆ†å‰²æˆå¤šå¤´
        queries = self.query(x_reshaped)  # [batch_size, 1, embed_size]
        keys = self.key(x_reshaped)       # [batch_size, 1, embed_size]
        values = self.value(x_reshaped)   # [batch_size, 1, embed_size]
        
        # å°†embed_sizeåˆ†å‰²æˆheadsä¸ªéƒ¨åˆ†
        queries = queries.reshape(batch_size, 1, self.heads, self.head_dim)
        keys = keys.reshape(batch_size, 1, self.heads, self.head_dim)
        values = values.reshape(batch_size, 1, self.heads, self.head_dim)
        
        # è°ƒæ•´ç»´åº¦é¡ºåºï¼Œä¾¿äºåç»­æ“ä½œ
        queries = queries.permute(0, 2, 1, 3)  # [batch_size, heads, 1, head_dim]
        keys = keys.permute(0, 2, 1, 3)        # [batch_size, heads, 1, head_dim]
        values = values.permute(0, 2, 1, 3)    # [batch_size, heads, 1, head_dim]
        
        # è®¡ç®—æ³¨æ„åŠ›åˆ†æ•°
        energy = torch.matmul(queries, keys.permute(0, 1, 3, 2))  # [batch_size, heads, 1, 1]
        
        # ç¼©æ”¾åˆ†æ•°
        energy = energy / self.scale
        
        # è®¡ç®—æ³¨æ„åŠ›æƒé‡
        attention = torch.softmax(energy, dim=-1)  # [batch_size, heads, 1, 1]
        
        # åº”ç”¨æ³¨æ„åŠ›æƒé‡
        out = torch.matmul(attention, values)  # [batch_size, heads, 1, head_dim]
        
        # é‡æ–°æ’åˆ—ç»´åº¦
        out = out.permute(0, 2, 1, 3)  # [batch_size, 1, heads, head_dim]
        
        # åˆå¹¶å¤šå¤´ç»“æœ
        out = out.reshape(batch_size, 1, self.heads * self.head_dim)  # [batch_size, 1, embed_size]
        
        # è¾“å‡ºå˜æ¢
        out = self.fc_out(out)  # [batch_size, 1, embed_size]
        
        # å»é™¤åºåˆ—ç»´åº¦
        out = out.squeeze(1)  # [batch_size, embed_size]
        
        return out, attention

class TransientPathway(nn.Module):
    """
    ç¬æ€è·¯å¾„ç½‘ç»œï¼Œå¤„ç†å‰15ä¸ªä¸»æˆåˆ†ï¼ˆç¬æ€ç‰¹å¾ï¼‰
    """
    def __init__(self, input_dim=15, hidden_dim=128, dropout=0.3):
        super(TransientPathway, self).__init__()
        
        # ç‰¹å¾æ‰©å±•å±‚
        self.feature_expansion = nn.Sequential(
            nn.Linear(input_dim, hidden_dim),
            nn.BatchNorm1d(hidden_dim),
            nn.LeakyReLU(),
            nn.Dropout(dropout)
        )
        
        # ä¸€ç»´å·ç§¯å±‚ï¼Œæå–å±€éƒ¨æ¨¡å¼
        self.conv_layers = nn.Sequential(
            nn.Conv1d(1, 32, kernel_size=3, padding=1),
            nn.BatchNorm1d(32),
            nn.LeakyReLU(),
            nn.Conv1d(32, 64, kernel_size=3, padding=1),
            nn.BatchNorm1d(64),
            nn.LeakyReLU(),
            nn.Dropout(dropout),
        )
        
        # ç‰¹å¾é‡æ–°æ˜ å°„
        self.feature_remap = nn.Sequential(
            nn.Linear(64 * hidden_dim, hidden_dim),
            nn.BatchNorm1d(hidden_dim),
            nn.LeakyReLU(),
            nn.Dropout(dropout)
        )
        
        # è‡ªæ³¨æ„åŠ›å±‚ï¼Œæ•æ‰ç‰¹å¾é—´çš„å…³ç³»
        self.attention = SelfAttention(hidden_dim)
        
        # è¾“å‡ºå±‚
        self.output_layer = nn.Sequential(
            nn.Linear(hidden_dim, hidden_dim),
            nn.BatchNorm1d(hidden_dim),
            nn.LeakyReLU(),
            nn.Dropout(dropout)
        )
    
    def forward(self, x):
        batch_size = x.size(0)
        
        # ç‰¹å¾æ‰©å±•
        x = self.feature_expansion(x)  # [batch_size, hidden_dim]
        
        # è°ƒæ•´è¾“å…¥ç»´åº¦ç”¨äºä¸€ç»´å·ç§¯ [batch_size, 1, hidden_dim]
        x = x.unsqueeze(1)
        
        # å·ç§¯å¤„ç†
        conv_out = self.conv_layers(x)  # [batch_size, 64, hidden_dim]
        
        # é‡å¡‘ä¸ºå…¨è¿æ¥å±‚è¾“å…¥
        conv_out = conv_out.reshape(batch_size, -1)  # [batch_size, 64 * hidden_dim]
        
        # ç‰¹å¾é‡æ–°æ˜ å°„
        mapped_features = self.feature_remap(conv_out)  # [batch_size, hidden_dim]
        
        # åº”ç”¨è‡ªæ³¨æ„åŠ›
        attended, _ = self.attention(mapped_features)  # [batch_size, hidden_dim]
        
        # è¾“å‡ºå±‚
        output = self.output_layer(attended)  # [batch_size, hidden_dim]
        
        return output

class SteadyPathway(nn.Module):
    """
    ç¨³æ€è·¯å¾„ç½‘ç»œï¼Œå¤„ç†å15ä¸ªä¸»æˆåˆ†ï¼ˆç¨³æ€ç‰¹å¾ï¼‰
    """
    def __init__(self, input_dim=15, hidden_dim=128, dropout=0.3):
        super(SteadyPathway, self).__init__()
        
        # ç‰¹å¾æ‰©å±•å±‚
        self.feature_expansion = nn.Sequential(
            nn.Linear(input_dim, hidden_dim),
            nn.BatchNorm1d(hidden_dim),
            nn.LeakyReLU(),
            nn.Dropout(dropout)
        )
        
        # 1D CNNç”¨äºé¢‘åŸŸåˆ†æ
        self.conv_layers = nn.Sequential(
            # ç¬¬ä¸€å±‚å·ç§¯
            nn.Conv1d(1, 32, kernel_size=3, padding=1),
            nn.BatchNorm1d(32),
            nn.LeakyReLU(),
            
            # ç¬¬äºŒå±‚å·ç§¯
            nn.Conv1d(32, 64, kernel_size=3, padding=1),
            nn.BatchNorm1d(64),
            nn.LeakyReLU(),
            nn.Dropout(dropout),
            
            # ç¬¬ä¸‰å±‚å·ç§¯
            nn.Conv1d(64, 128, kernel_size=3, padding=1),
            nn.BatchNorm1d(128),
            nn.LeakyReLU(),
        )
        
        # è‡ªé€‚åº”æ± åŒ–å±‚
        self.adaptive_pool = nn.AdaptiveAvgPool1d(1)
        
        # å…¨è¿æ¥å±‚
        self.fc_layers = nn.Sequential(
            nn.Linear(128, hidden_dim),
            nn.BatchNorm1d(hidden_dim),
            nn.LeakyReLU(),
            nn.Dropout(dropout)
        )
        
        # è‡ªæ³¨æ„åŠ›å±‚
        self.attention = SelfAttention(hidden_dim)
        
    def forward(self, x):
        batch_size = x.size(0)
        
        # ç‰¹å¾æ‰©å±•
        x = self.feature_expansion(x)  # [batch_size, hidden_dim]
        
        # å°†ç‰¹å¾é‡å¡‘ä¸ºé€‚åˆCNNçš„å½¢çŠ¶ [batch_size, 1, hidden_dim]
        x = x.unsqueeze(1)
        
        # åº”ç”¨å·ç§¯å±‚
        x = self.conv_layers(x)  # [batch_size, 128, hidden_dim]
        
        # åº”ç”¨è‡ªé€‚åº”æ± åŒ–
        x = self.adaptive_pool(x)  # [batch_size, 128, 1]
        x = x.squeeze(2)  # [batch_size, 128]
        
        # åº”ç”¨å…¨è¿æ¥å±‚
        x = self.fc_layers(x)  # [batch_size, hidden_dim]
        
        # åº”ç”¨è‡ªæ³¨æ„åŠ›
        x, _ = self.attention(x)  # [batch_size, hidden_dim]
        
        return x

class DualPathNetwork(nn.Module):
    """
    åŒè·¯å¾„ç½‘ç»œï¼Œé€‚åº”åˆ†ç»„PCAé™ç»´åçš„æ•°æ®æ ¼å¼
    """
    def __init__(self, num_classes, hidden_dim=128):
        super(DualPathNetwork, self).__init__()
        
        # ç¬æ€è·¯å¾„ - å¤„ç†å‰15ä¸ªä¸»æˆåˆ†
        self.transient_pathway = TransientPathway(input_dim=15, hidden_dim=hidden_dim)
        
        # ç¨³æ€è·¯å¾„ - å¤„ç†å15ä¸ªä¸»æˆåˆ†
        self.steady_pathway = SteadyPathway(input_dim=15, hidden_dim=hidden_dim)
        
        # ç‰¹å¾èåˆå±‚
        self.fusion_layer = nn.Sequential(
            nn.Linear(hidden_dim * 2, hidden_dim),
            nn.BatchNorm1d(hidden_dim),
            nn.ReLU(),
            nn.Dropout(0.3)
        )
        
        # åˆ†ç±»å™¨
        self.classifier = nn.Sequential(
            nn.Linear(hidden_dim, hidden_dim // 2),
            nn.BatchNorm1d(hidden_dim // 2),
            nn.ReLU(),
            nn.Dropout(0.3),
            nn.Linear(hidden_dim // 2, num_classes)
        )
        
    def forward(self, x):
        # åˆ†å‰²è¾“å…¥ç‰¹å¾
        # x: [batch_size, 30] - 30ä¸ªä¸»æˆåˆ† (15ç¬æ€ + 15ç¨³æ€)
        x_transient = x[:, :15]   # å‰15ä¸ªä¸»æˆåˆ†ä½œä¸ºç¬æ€ç‰¹å¾
        x_steady = x[:, 15:]      # å15ä¸ªä¸»æˆåˆ†ä½œä¸ºç¨³æ€ç‰¹å¾
        
        # å¤„ç†ç¬æ€ç‰¹å¾
        transient_features = self.transient_pathway(x_transient)
        
        # å¤„ç†ç¨³æ€ç‰¹å¾
        steady_features = self.steady_pathway(x_steady)
        
        # ç‰¹å¾èåˆ
        combined_features = torch.cat([transient_features, steady_features], dim=1)
        fused_features = self.fusion_layer(combined_features)
        
        # åˆ†ç±»
        logits = self.classifier(fused_features)
        
        return logits

class SimplifiedCNNPath(nn.Module):
    """ç®€åŒ–çš„CNNè·¯å¾„ï¼Œé€‚åº”åˆ†ç»„é™ç»´åçš„æ•°æ®"""
    def __init__(self, input_dim, num_classes, dropout=0.3):
        super(SimplifiedCNNPath, self).__init__()
        
        self.network = nn.Sequential(
            nn.Linear(input_dim, 128),
            nn.BatchNorm1d(128),
            nn.ReLU(),
            nn.Dropout(dropout),
            nn.Linear(128, 64),
            nn.BatchNorm1d(64),
            nn.ReLU(),
            nn.Dropout(dropout),
            nn.Linear(64, num_classes)
        )
    
    def forward(self, x):
        return self.network(x)

class RobustLNNPath(nn.Module):
    """å¢å¼ºçš„LNNè·¯å¾„ï¼Œæ›´å¥½åœ°å¤„ç†å™ªå£°ç¯å¢ƒ"""
    def __init__(self, input_dim, num_classes, dropout=0.3):
        super(RobustLNNPath, self).__init__()
        
        # è¾“å…¥æŠ•å½±å±‚
        self.input_projection = nn.Sequential(
            nn.Linear(input_dim, 96),
            nn.BatchNorm1d(96),
            nn.GELU(),
            nn.Dropout(dropout/2)
        )
        
        # ä½¿ç”¨å¤šå±‚GRUæé«˜å™ªå£°é²æ£’æ€§
        self.gru = nn.GRU(input_size=96, 
                          hidden_size=48, 
                          num_layers=2,
                          batch_first=True,
                          dropout=0.2,
                          bidirectional=True)
        
        # æ³¨æ„åŠ›æœºåˆ¶ï¼Œå¢å¼ºå¯¹å…³é”®ç‰¹å¾çš„å…³æ³¨
        self.attention = nn.Sequential(
            nn.Linear(96, 64),
            nn.Tanh(),
            nn.Linear(64, 1)
        )
        
        self.output = nn.Sequential(
            nn.Linear(96, num_classes),
            nn.Dropout(dropout)
        )
    
    def forward(self, x):
        # è¾“å…¥æŠ•å½±
        x = self.input_projection(x)  # [batch, 96]
        
        # æ·»åŠ æ—¶é—´ç»´åº¦å¹¶é‡å¤è¾“å…¥åˆ›å»ºåºåˆ—
        batch_size = x.size(0)
        x_repeated = x.unsqueeze(1).repeat(1, 3, 1)  # [batch, 3, 96]
        
        # GRUå¤„ç†
        out, _ = self.gru(x_repeated)  # [batch, 3, 96]
        
        # æ³¨æ„åŠ›æœºåˆ¶
        attn_weights = self.attention(out)  # [batch, 3, 1]
        attn_weights = F.softmax(attn_weights, dim=1)
        
        # åŠ æƒæ±‡æ€»
        context = torch.sum(out * attn_weights, dim=1)  # [batch, 96]
        
        # è¾“å‡ºå±‚
        return self.output(context)

class ImprovedAdaptiveWeightedLoss(nn.Module):
    """æ”¹è¿›çš„è‡ªé€‚åº”åŠ æƒæŸå¤±å‡½æ•°"""
    def __init__(self, num_classes, snr_guidance_weight=0.1):
        super(ImprovedAdaptiveWeightedLoss, self).__init__()
        self.ce_loss = nn.CrossEntropyLoss(reduction='none', label_smoothing=0.1)  # å¢åŠ æ ‡ç­¾å¹³æ»‘
        self.num_classes = num_classes
        self.snr_guidance_weight = snr_guidance_weight
    
    def forward(self, final_logits, cnn_logits, lnn_logits, targets, snr, model_weights):
        # è®¡ç®—å„ä¸ªåˆ†æ”¯çš„æŸå¤±
        cnn_loss = self.ce_loss(cnn_logits, targets).mean()
        lnn_loss = self.ce_loss(lnn_logits, targets).mean()
        ensemble_loss = self.ce_loss(final_logits, targets).mean()
        
        # å½’ä¸€åŒ–SNR
        normalized_snr = torch.clamp(snr / 30.0, -1.0, 1.0)
        
        # å¹³è¡¡æƒé‡æŸå¤±
        weight_balance_loss = torch.abs(model_weights[:, 0] - model_weights[:, 1]).mean()
        
        # é«˜SNRæ—¶å¼•å¯¼CNNåˆ†æ”¯
        high_snr_mask = (normalized_snr > 0.3).squeeze()
        high_snr_guidance = torch.zeros_like(ensemble_loss)
        if high_snr_mask.any():
            cnn_weight_loss = F.relu(0.7 - model_weights[high_snr_mask, 0]).mean()
            high_snr_guidance = cnn_weight_loss * self.snr_guidance_weight
        
        # ä½SNRæ—¶å¼•å¯¼LNNåˆ†æ”¯
        low_snr_mask = (normalized_snr < -0.3).squeeze()
        low_snr_guidance = torch.zeros_like(ensemble_loss)
        if low_snr_mask.any():
            lnn_weight_loss = F.relu(0.7 - model_weights[low_snr_mask, 1]).mean()
            low_snr_guidance = lnn_weight_loss * self.snr_guidance_weight
        
        # æ€»æŸå¤±
        total_loss = ensemble_loss + 0.2 * (cnn_loss + lnn_loss) + \
                     0.1 * weight_balance_loss + high_snr_guidance + low_snr_guidance
        
        component_losses = {
            'cnn_loss': cnn_loss.item(),
            'lnn_loss': lnn_loss.item(),
            'ensemble_loss': ensemble_loss.item(),
            'weight_balance_loss': weight_balance_loss.item(),
            'weighted_loss': total_loss.item()
        }
        
        return total_loss, component_losses

class ImprovedEnsembleADSBNetwork(nn.Module):
    """æ”¹è¿›çš„é›†æˆADS-Bç½‘ç»œ - é€‚é…åˆ†ç»„æ•°æ®"""
    def __init__(self, input_dim=30, num_classes=107, hidden_dim=128):
        super(ImprovedEnsembleADSBNetwork, self).__init__()
        self.num_classes = num_classes
        
        # ç‰¹å¾é¢„å¤„ç†å±‚
        self.feature_processor = nn.Sequential(
            nn.Linear(input_dim, hidden_dim * 2),
            nn.BatchNorm1d(hidden_dim * 2),
            nn.GELU(),
            nn.Dropout(0.2)
        )
        
        # ç‰¹å¾åˆ†å‰²ï¼šå‰ä¸€åŠä½œä¸ºç¬æ€ç‰¹å¾ï¼Œåä¸€åŠä½œä¸ºç¨³æ€ç‰¹å¾
        self.transient_extractor = nn.Sequential(
            nn.Linear(hidden_dim, hidden_dim),
            nn.BatchNorm1d(hidden_dim),
            nn.GELU(),
            nn.Dropout(0.2)
        )
        
        self.steady_extractor = nn.Sequential(
            nn.Linear(hidden_dim, hidden_dim),
            nn.BatchNorm1d(hidden_dim),
            nn.GELU(),
            nn.Dropout(0.2)
        )
        
        # èåˆç‰¹å¾å¤„ç†
        self.fused_extractor = nn.Sequential(
            nn.Linear(hidden_dim * 2, hidden_dim * 2),
            nn.BatchNorm1d(hidden_dim * 2),
            nn.ReLU(),
            nn.Dropout(0.2)
        )
        
        # ä¸¤ä¸ªä¸»è¦æ¨¡å‹åˆ†æ”¯
        self.cnn_model = SimplifiedCNNPath(hidden_dim * 2, num_classes)
        self.lnn_model = RobustLNNPath(hidden_dim * 2, num_classes)
        
        # SNRä¼°è®¡å™¨
        self.snr_estimator_freq = nn.Sequential(
            nn.Linear(hidden_dim * 2, 128),
            nn.LayerNorm(128),
            nn.LeakyReLU(),
            nn.Dropout(0.2),
            nn.Linear(128, 64),
            nn.LayerNorm(64),
            nn.LeakyReLU(),
            nn.Linear(64, 32),
            nn.LeakyReLU()
        )
        
        self.snr_estimator_energy = nn.Sequential(
            nn.Linear(hidden_dim * 2, 64),
            nn.LayerNorm(64),
            nn.ReLU(),
            nn.Dropout(0.2),
            nn.Linear(64, 32),
            nn.ReLU()
        )
        
        self.snr_peak_estimator = nn.Sequential(
            nn.Linear(hidden_dim * 2, 32),
            nn.LeakyReLU(),
            nn.Linear(32, 16),
            nn.LeakyReLU()
        )
        
        self.snr_fusion = nn.Sequential(
            nn.Linear(32 + 32 + 16, 32),
            nn.LayerNorm(32),
            nn.LeakyReLU(),
            nn.Linear(32, 16),
            nn.LeakyReLU(),
            nn.Linear(16, 1),
            nn.Tanh()
        )
        
        # æƒé‡åˆ†é…ç½‘ç»œï¼šåªè¾“å‡º2ä¸ªåˆ†æ”¯æƒé‡
        self.weight_net_fc1 = nn.Linear(1, 64)
        self.weight_net_fc2 = nn.Linear(64, 32)
        self.weight_net_out = nn.Linear(32, 2)
        
        # èåˆå±‚
        encoder_layer = nn.TransformerEncoderLayer(d_model=num_classes, nhead=1, dim_feedforward=64, dropout=0.1, batch_first=True)
        self.transformer_fusion = nn.TransformerEncoder(encoder_layer, num_layers=1)
        self.fusion_fc = nn.Linear(num_classes, num_classes)
        
        self._initialize_weights()
    
    def _initialize_weights(self):
        with torch.no_grad():
            nn.init.xavier_normal_(self.weight_net_fc1.weight)
            nn.init.xavier_normal_(self.weight_net_fc2.weight)
            nn.init.xavier_normal_(self.weight_net_out.weight)
            self.weight_net_out.bias.fill_(0.0)
    
    def _compute_adaptive_weights(self, snr):
        if snr.dim() > 1 and snr.size(1) == 1:
            x = snr
        else:
            x = snr.unsqueeze(1) if snr.dim() == 1 else snr
        x = F.leaky_relu(self.weight_net_fc1(x))
        x = F.leaky_relu(self.weight_net_fc2(x))
        weights_logits = self.weight_net_out(x)
        weights = F.softmax(weights_logits, dim=1)
        return weights
    
    def forward(self, x):
        # ç‰¹å¾é¢„å¤„ç†
        processed_features = self.feature_processor(x)
        
        # åˆ†å‰²ç‰¹å¾ä¸ºç¬æ€å’Œç¨³æ€éƒ¨åˆ†
        mid_dim = processed_features.size(1) // 2
        trans_part = processed_features[:, :mid_dim]
        steady_part = processed_features[:, mid_dim:]
        
        # ç‰¹å¾æå–
        trans_features = self.transient_extractor(trans_part)
        steady_features = self.steady_extractor(steady_part)
        
        # èåˆç‰¹å¾
        combined = torch.cat([trans_features, steady_features], dim=1)
        features = self.fused_extractor(combined)
        
        # SNRä¼°è®¡
        snr_freq = self.snr_estimator_freq(features)
        snr_energy = self.snr_estimator_energy(features)
        snr_peak = self.snr_peak_estimator(features)
        snr_combined = torch.cat([snr_freq, snr_energy, snr_peak], dim=1)
        snr = self.snr_fusion(snr_combined) * 30
        
        # è·å–ä¸¤ä¸ªæ¨¡å‹çš„è¾“å‡º
        cnn_logits = self.cnn_model(features)
        lnn_logits = self.lnn_model(features)
        
        # è®¡ç®—è‡ªé€‚åº”æƒé‡
        weights = self._compute_adaptive_weights(snr)
        
        # åŠ æƒèåˆ
        weighted_cnn = cnn_logits * weights[:, 0].unsqueeze(1)
        weighted_lnn = lnn_logits * weights[:, 1].unsqueeze(1)
        
        # Transformerèåˆ
        fusion_seq = torch.stack([weighted_cnn, weighted_lnn], dim=1)
        fusion_out = self.transformer_fusion(fusion_seq)
        fusion_pooled = fusion_out.mean(dim=1)
        final_logits = self.fusion_fc(fusion_pooled)
        
        return final_logits, snr, weights

def add_advanced_noise_to_batch(batch_x, min_snr=-10, max_snr=20, snr_high=0.90, snr_mid=0.09, snr_low=0.01):
    """ä¸ºæ‰¹æ¬¡æ•°æ®æ·»åŠ æ›´é«˜çº§çš„å™ªå£°æ¨¡å‹"""
    batch_size = batch_x.size(0)
    noisy_x = torch.zeros_like(batch_x)
    
    # SNRåŒºé—´
    snr_weights = {
        (15, 20): snr_high,
        (5, 15): snr_mid,
        (min_snr, 5): snr_low
    }
    
    def add_complex_noise(signal, snr_db):
        """æ·»åŠ å¤æ‚å™ªå£°æ¨¡å‹ï¼ŒåŒ…æ‹¬é«˜æ–¯ã€è„‰å†²å’Œé¢‘åŸŸå™ªå£°"""
        signal_numpy = signal.detach().cpu().numpy()
        signal_power = np.mean(signal_numpy ** 2)
        noise_power = signal_power / (10 ** (snr_db / 10))
        noise = np.random.normal(0, np.sqrt(noise_power), signal_numpy.shape)
        
        # å¯¹äºä½SNRï¼Œæ·»åŠ é¢å¤–çš„å™ªå£°ç±»å‹
        if snr_db < 0:
            # æ·»åŠ è„‰å†²å™ªå£°
            impulse_mask = np.random.rand(*signal_numpy.shape) < 0.05
            impulse_noise = np.random.randn(*signal_numpy.shape) * 3
            signal_numpy[impulse_mask] += impulse_noise[impulse_mask]
        
        noisy_signal = signal_numpy + noise
        return torch.FloatTensor(noisy_signal)
    
    # ä¸ºæ¯ä¸ªæ ·æœ¬é€‰æ‹©SNRå¹¶æ·»åŠ å™ªå£°
    actual_snrs = []
    for i in range(batch_size):
        # éšæœºé€‰æ‹©SNRèŒƒå›´
        snr_range = random.choices(list(snr_weights.keys()), weights=list(snr_weights.values()), k=1)[0]
        
        # åœ¨é€‰å®šèŒƒå›´å†…å‡åŒ€éšæœºé€‰æ‹©SNRå€¼
        snr_db = snr_range[0] + (snr_range[1] - snr_range[0]) * random.random()
        actual_snrs.append(snr_db)
        
        # æ·»åŠ å¤æ‚å™ªå£°
        noisy_x[i] = add_complex_noise(batch_x[i], snr_db)
    
    return noisy_x, actual_snrs

class NoiseDataLoader:
    """æ·»åŠ å™ªå£°çš„æ•°æ®åŠ è½½å™¨"""
    def __init__(self, dataset, batch_size=32, shuffle=True, 
                noise_prob=0.5, min_snr=-10, max_snr=20):
        self.dataset = dataset
        self.batch_size = batch_size
        self.shuffle = shuffle
        self.noise_prob = noise_prob
        self.min_snr = min_snr
        self.max_snr = max_snr
        
        # åˆ›å»ºåŸå§‹æ•°æ®åŠ è½½å™¨
        self.dataloader = DataLoader(
            dataset, 
            batch_size=batch_size, 
            shuffle=shuffle
        )
    
    def __iter__(self):
        self.iterator = iter(self.dataloader)
        return self
    
    def __next__(self):
        # è·å–ä¸‹ä¸€æ‰¹æ•°æ®
        batch_x, batch_y = next(self.iterator)
        
        # ä¸ºæ¯ä¸ªæ ·æœ¬ç”ŸæˆéšæœºSNRå€¼
        batch_size = batch_x.size(0)
        batch_snr = torch.zeros(batch_size, 1)
        
        # æœ‰ä¸€å®šæ¦‚ç‡æ·»åŠ å™ªå£°
        if random.random() < self.noise_prob:
            batch_x, actual_snrs = add_advanced_noise_to_batch(
                batch_x, 
                min_snr=self.min_snr, max_snr=self.max_snr
            )
            batch_snr = torch.tensor(actual_snrs).float().unsqueeze(1)
        else:
            # å¦‚æœä¸æ·»åŠ å™ªå£°ï¼Œå‡è®¾SNRä¸ºæœ€å¤§å€¼
            batch_snr.fill_(self.max_snr)
        
        return batch_x, batch_y, batch_snr
    
    def __len__(self):
        return len(self.dataloader)

class NoisySampler:
    """è®­ç»ƒæ—¶åŠ¨æ€é€‰æ‹©éƒ¨åˆ†æ•°æ®å¹¶æ·»åŠ å™ªå£°çš„é‡‡æ ·å™¨"""
    def __init__(self, dataset, subset_ratio=0.3, change_epochs=5, 
                noise_prob=0.5, min_snr=-15, max_snr=25):
        self.dataset = dataset
        self.subset_ratio = subset_ratio
        self.change_epochs = change_epochs
        self.noise_prob = noise_prob
        self.min_snr = min_snr
        self.max_snr = max_snr
        self.current_subset = None
        self.epoch = 0
        
        # åˆå§‹åŒ–å­é›†
        self._create_new_subset()
    
    def _create_new_subset(self):
        """åˆ›å»ºæ–°çš„å­é›†"""
        dataset_size = len(self.dataset)
        subset_size = int(dataset_size * self.subset_ratio)
        
        # éšæœºé€‰æ‹©ç´¢å¼•
        indices = torch.randperm(dataset_size)[:subset_size].tolist()
        self.current_subset = Subset(self.dataset, indices)
    
    def get_loader(self, batch_size, shuffle=True):
        """è·å–å½“å‰å­é›†çš„æ•°æ®åŠ è½½å™¨"""
        return NoiseDataLoader(
            self.current_subset, 
            batch_size=batch_size, 
            shuffle=shuffle,
            noise_prob=self.noise_prob,
            min_snr=self.min_snr,
            max_snr=self.max_snr
        )
    
    def next_epoch(self):
        """è¿›å…¥ä¸‹ä¸€ä¸ªepochï¼Œå¿…è¦æ—¶æ›´æ–°å­é›†"""
        self.epoch += 1
        
        # æ¯change_epochsä¸ªepochæ›´æ¢ä¸€æ¬¡å­é›†
        if self.epoch % self.change_epochs == 0:
            self._create_new_subset()

def train_improved_ensemble(
        model, 
        train_dataset, 
        val_dataset, 
        num_epochs=40, 
        batch_size=32, 
        subset_ratio=0.5,
        change_epochs=5,
        noise_prob=0.7,
        min_snr=-10,
        max_snr=20,
        lr=0.001,
        save_dir='./improved_ensemble_results',
        snr_high=0.90,
        snr_mid=0.09,
        snr_low=0.01
    ):
    """
    è®­ç»ƒæ”¹è¿›çš„é›†æˆæ¨¡å‹ï¼Œå¢å¼ºä½SNRç¯å¢ƒä¸‹çš„æ€§èƒ½
    """
    import os
    import time
    from tqdm import tqdm
    
    # åˆ›å»ºç»“æœç›®å½•
    os.makedirs(save_dir, exist_ok=True)
    
    # è®¾ç½®æ—¥å¿—è®°å½•å™¨
    logger = setup_logger(save_dir)
    
    # è®¾ç½®è®¾å¤‡
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    logger.info(f"ä½¿ç”¨è®¾å¤‡: {device}")
    
    model = model.to(device)
    
    # å®šä¹‰æŸå¤±å‡½æ•°å’Œä¼˜åŒ–å™¨
    criterion = ImprovedAdaptiveWeightedLoss(num_classes=model.fusion_fc.out_features)
    optimizer = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=1e-4)
    
    # ä½¿ç”¨ä½™å¼¦é€€ç«è°ƒåº¦å™¨ï¼Œå¸¦æœ‰çƒ­å¯åŠ¨
    scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(
        optimizer, T_0=5, T_mult=2, eta_min=lr/20
    )
    
    # åˆ›å»ºå¸¦å™ªå£°çš„æ•°æ®é‡‡æ ·å™¨
    sampler = NoisySampler(
        train_dataset, 
        subset_ratio=subset_ratio, 
        change_epochs=change_epochs,
        noise_prob=noise_prob,
        min_snr=min_snr,
        max_snr=max_snr
    )
    
    # åˆ›å»ºéªŒè¯æ•°æ®åŠ è½½å™¨
    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)
    
    # è®­ç»ƒå†å²
    history = {
        'train_loss': [],
        'train_acc': [],
        'val_loss': [],
        'val_acc': [],
        'epoch_time': [],
        'mean_weights': []
    }
    
    # æœ€ä½³æ¨¡å‹è¿½è¸ª
    best_val_acc = 0.0
    best_model_epoch = 0
    patience = 15  # æ—©åœå®¹å¿æ¬¡æ•°
    early_stop_counter = 0
    
    logger.info(f"å¼€å§‹è®­ç»ƒæ”¹è¿›çš„é›†æˆæ¨¡å‹ï¼Œä½¿ç”¨{subset_ratio*100:.1f}%çš„æ•°æ®...")
    logger.info(f"å™ªå£°æ·»åŠ æ¦‚ç‡: {noise_prob*100:.1f}%, ä¿¡å™ªæ¯”èŒƒå›´: [{min_snr}, {max_snr}] dB")
    
    for epoch in range(num_epochs):
        # æ›´æ–°å­é›†
        sampler.next_epoch()
        # ä½¿ç”¨æ”¹è¿›çš„æ•°æ®åŠ è½½å™¨
        train_loader = sampler.get_loader(batch_size, shuffle=True)
        
        # åˆå§‹åŒ–æœ¬epochçš„SNRæ”¶é›†åˆ—è¡¨
        epoch_snrs = []
        
        # è®­ç»ƒé˜¶æ®µ
        model.train()
        train_loss = 0.0
        train_correct = 0
        train_total = 0
        epoch_weights = []
        
        epoch_start_time = time.time()
        
        # è®­ç»ƒå¾ªç¯
        for batch_idx, batch_data in enumerate(tqdm(train_loader, desc=f"Epoch {epoch+1}/{num_epochs}")):
            # è§£åŒ…æ•°æ® - æ³¨æ„ç°åœ¨è¿”å›3ä¸ªå€¼ï¼ŒåŒ…æ‹¬SNR
            batch_x, batch_y, batch_snr = batch_data
            batch_x, batch_y, batch_snr = (
                batch_x.to(device), 
                batch_y.to(device),
                batch_snr.to(device)
            )
            # æ”¶é›†æœ¬batchçš„SNR
            epoch_snrs.extend(batch_snr.cpu().numpy().flatten().tolist())
            
            # æ¸…é›¶æ¢¯åº¦
            optimizer.zero_grad()
            
            # å‰å‘ä¼ æ’­
            final_logits, snr, model_weights = model(batch_x)
            # è·å–å„åˆ†æ”¯logits
            with torch.no_grad():
                # é‡æ–°è®¡ç®—ç‰¹å¾
                processed_features = model.feature_processor(batch_x)
                mid_dim = processed_features.size(1) // 2
                trans_part = processed_features[:, :mid_dim]
                steady_part = processed_features[:, mid_dim:]
                trans_features = model.transient_extractor(trans_part)
                steady_features = model.steady_extractor(steady_part)
                combined = torch.cat([trans_features, steady_features], dim=1)
                features = model.fused_extractor(combined)
                cnn_logits = model.cnn_model(features)
                lnn_logits = model.lnn_model(features)
            
            # æŸå¤±å‡½æ•°è°ƒç”¨
            loss, component_losses = criterion(final_logits, cnn_logits, lnn_logits, batch_y, snr, model_weights)
            
            # åå‘ä¼ æ’­
            loss.backward()
            
            # æ¢¯åº¦è£å‰ª
            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=3.0)
            
            # ä¼˜åŒ–æ­¥éª¤
            optimizer.step()
            
            # ç»Ÿè®¡
            train_loss += loss.item() * batch_y.size(0)
            _, predicted = torch.max(final_logits, 1)
            train_total += batch_y.size(0)
            train_correct += (predicted == batch_y).sum().item()
            
            # è®°å½•æƒé‡
            epoch_weights.append(model_weights.detach().cpu())
        
        # è®¡ç®—å¹³å‡è®­ç»ƒæŸå¤±å’Œå‡†ç¡®ç‡
        train_loss = train_loss / train_total
        train_accuracy = train_correct / train_total
        
        # è®¡ç®—å¹³å‡æƒé‡
        epoch_weights = torch.cat(epoch_weights, dim=0)
        mean_weights = epoch_weights.mean(dim=0).numpy()
        
        # éªŒè¯é˜¶æ®µ - æ¯2ä¸ªepochéªŒè¯ä¸€æ¬¡
        if epoch % 2 == 0 or epoch == num_epochs - 1:
            model.eval()
            val_loss = 0.0
            val_correct = 0
            val_total = 0
            
            with torch.no_grad():
                for batch_x, batch_y in val_loader:
                    batch_x, batch_y = batch_x.to(device), batch_y.to(device)
                    
                    # å‰å‘ä¼ æ’­
                    final_logits, snr, model_weights = model(batch_x)
                    # è·å–å„åˆ†æ”¯logits
                    processed_features = model.feature_processor(batch_x)
                    mid_dim = processed_features.size(1) // 2
                    trans_part = processed_features[:, :mid_dim]
                    steady_part = processed_features[:, mid_dim:]
                    trans_features = model.transient_extractor(trans_part)
                    steady_features = model.steady_extractor(steady_part)
                    combined = torch.cat([trans_features, steady_features], dim=1)
                    features = model.fused_extractor(combined)
                    cnn_logits = model.cnn_model(features)
                    lnn_logits = model.lnn_model(features)
                    
                    # æŸå¤±å‡½æ•°è°ƒç”¨
                    loss, _ = criterion(final_logits, cnn_logits, lnn_logits, batch_y, snr, model_weights)
                    
                    # ç»Ÿè®¡
                    val_loss += loss.item() * batch_y.size(0)
                    _, predicted = torch.max(final_logits, 1)
                    val_total += batch_y.size(0)
                    val_correct += (predicted == batch_y).sum().item()
            
            # è®¡ç®—å¹³å‡éªŒè¯æŸå¤±å’Œå‡†ç¡®ç‡
            val_loss = val_loss / val_total
            val_accuracy = val_correct / val_total
            
            # ä¿å­˜æœ€ä½³æ¨¡å‹
            if val_accuracy > best_val_acc:
                best_val_acc = val_accuracy
                best_model_epoch = epoch + 1
                torch.save(model.state_dict(), os.path.join(save_dir, 'best_improved_model.pth'))
                logger.info(f"ä¿å­˜æ–°çš„æœ€ä½³æ¨¡å‹ï¼ŒéªŒè¯å‡†ç¡®ç‡: {val_accuracy:.4f}")
                early_stop_counter = 0
            else:
                early_stop_counter += 1
                logger.info(f"éªŒè¯é›†å‡†ç¡®ç‡è¿ç»­æœªæå‡æ¬¡æ•°: {early_stop_counter}/{patience}")
                if early_stop_counter >= patience:
                    logger.info(f"æ—©åœè§¦å‘ï¼éªŒè¯é›†å‡†ç¡®ç‡è¿ç»­{patience}æ¬¡æœªæå‡ï¼Œæå‰ç»ˆæ­¢è®­ç»ƒã€‚")
                    break
        else:
            # æœªè¿›è¡ŒéªŒè¯çš„epochä½¿ç”¨ä¸Šä¸€ä¸ªç»“æœ
            val_loss = history['val_loss'][-1] if history['val_loss'] else float('inf')
            val_accuracy = history['val_acc'][-1] if history['val_acc'] else 0.0
        
        # æ›´æ–°å­¦ä¹ ç‡
        scheduler.step()
        
        # è®¡ç®—epochç”¨æ—¶
        epoch_time = time.time() - epoch_start_time
        
        # ä¿å­˜è®­ç»ƒå†å²
        history['train_loss'].append(train_loss)
        history['train_acc'].append(train_accuracy)
        history['val_loss'].append(val_loss)
        history['val_acc'].append(val_accuracy)
        history['epoch_time'].append(epoch_time)
        history['mean_weights'].append(mean_weights)
        
        # è®°å½•è®­ç»ƒä¿¡æ¯åˆ°æ—¥å¿—
        logger.info(f"Epoch {epoch+1}/{num_epochs} - "
                   f"Train Loss: {train_loss:.4f}, Train Acc: {train_accuracy:.4f}, "
                   f"Val Loss: {val_loss:.4f}, Val Acc: {val_accuracy:.4f}, "
                   f"Time: {epoch_time:.2f}s, LR: {optimizer.param_groups[0]['lr']:.6f}")
        
        # è®°å½•æƒé‡åˆ†å¸ƒåˆ°æ—¥å¿—
        if epoch % 5 == 0 or epoch == num_epochs - 1:
            logger.info(f"å¹³å‡æƒé‡åˆ†å¸ƒ - CNN: {mean_weights[0]:.3f}, LNN: {mean_weights[1]:.3f}")
        
        # è®°å½•SNRåˆ†å¸ƒåˆ°æ—¥å¿—
        logger.info(f"Epoch {epoch+1} SNRåˆ†å¸ƒ: å‡å€¼={np.mean(epoch_snrs):.2f}, æ–¹å·®={np.var(epoch_snrs):.2f}")
    
    # åŠ è½½æœ€ä½³æ¨¡å‹
    model.load_state_dict(torch.load(os.path.join(save_dir, 'best_improved_model.pth')))
    
    # ç»˜åˆ¶è®­ç»ƒå†å²
    plt.figure(figsize=(15, 10))
    
    # æŸå¤±æ›²çº¿
    plt.subplot(2, 2, 1)
    epochs = range(1, len(history['train_loss']) + 1)
    plt.plot(epochs, history['train_loss'], 'b-', label='training loss')
    plt.plot(epochs, history['val_loss'], 'r-', label='validation loss')
    plt.title('Training and Validation Loss')
    plt.xlabel('Epochs')
    plt.ylabel('Loss')
    plt.legend()
    plt.grid(True)
    
    # å‡†ç¡®ç‡æ›²çº¿
    plt.subplot(2, 2, 2)
    plt.plot(epochs, history['train_acc'], 'b-', label='training accuracy')
    plt.plot(epochs, history['val_acc'], 'r-', label='validation accuracy')
    plt.title('Training and Validation Accuracy')
    plt.xlabel('Epochs')
    plt.ylabel('Accuracy')
    plt.legend()
    plt.grid(True)
    
    # æƒé‡åˆ†å¸ƒæ›²çº¿
    plt.subplot(2, 2, 3)
    weights_array = np.array(history['mean_weights'])
    plt.plot(epochs, weights_array[:, 0], 'r-', label='CNN weights')
    plt.plot(epochs, weights_array[:, 1], 'g-', label='LNN weights')
    plt.title('Model Weights Distribution Evolution')
    plt.xlabel('Epochs')
    plt.ylabel('Average Weights')
    plt.legend()
    plt.grid(True)
    
    plt.tight_layout()
    plt.savefig(os.path.join(save_dir, 'improved_training_history.png'), dpi=300)
    plt.close()
    
    logger.info(f"è®­ç»ƒå®Œæˆï¼æœ€ä½³éªŒè¯å‡†ç¡®ç‡: {best_val_acc:.4f} (Epoch {best_model_epoch})")
    logger.info(f"å¹³å‡æ¯ä¸ªepochè€—æ—¶: {np.mean(history['epoch_time']):.2f}ç§’")
    
    return model, best_val_acc

def test_snr_performance_improved(
        model, 
        test_dataset, 
        snr_range=None, 
        batch_size=32, 
        save_dir='./improved_ensemble_results'
    ):
    """æµ‹è¯•æ”¹è¿›æ¨¡å‹åœ¨ä¸åŒSNRä¸‹çš„æ€§èƒ½"""
    # å¦‚æœæ²¡æœ‰æŒ‡å®šSNRèŒƒå›´ï¼Œä½¿ç”¨é»˜è®¤å€¼
    if snr_range is None:
        snr_range = [20, 15, 10, 5, 0, -5, -10]
    
    # è®¾ç½®è®¾å¤‡
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    model = model.to(device)
    model.eval()
    
    # å‡†å¤‡æµ‹è¯•ç»“æœ
    results = {
        'snr_db': snr_range,
        'accuracy': [],
        'cnn_weight': [],
        'lnn_weight': []
    }
    
    # æµ‹è¯•æ¯ä¸ªSNR
    for snr_db in snr_range:
        print(f"æµ‹è¯•SNR = {snr_db} dBçš„æ€§èƒ½...")
        
        # åˆ›å»ºæµ‹è¯•åŠ è½½å™¨
        test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)
        
        # è¯„ä¼°æŒ‡æ ‡
        correct = 0
        total = 0
        all_weights = []
        
        with torch.no_grad():
            for batch_x, batch_y in test_loader:
                # æ·»åŠ æŒ‡å®šSNRçš„å™ªå£°
                batch_x, _ = add_advanced_noise_to_batch(
                    batch_x, 
                    min_snr=snr_db, max_snr=snr_db  # å›ºå®šSNRå€¼
                )
                
                # è½¬ç§»åˆ°è®¾å¤‡
                batch_x = batch_x.to(device)
                batch_y = batch_y.to(device)
                
                # å‰å‘ä¼ æ’­
                final_logits, snr, weights = model(batch_x)
                
                # ç»Ÿè®¡é¢„æµ‹ç»“æœ
                _, predicted = torch.max(final_logits, 1)
                total += batch_y.size(0)
                correct += (predicted == batch_y).sum().item()
                
                # æ”¶é›†æƒé‡
                all_weights.append(weights.cpu())
        
        # è®¡ç®—å‡†ç¡®ç‡å’Œå¹³å‡æƒé‡
        accuracy = correct / total
        all_weights = torch.cat(all_weights, dim=0)
        avg_weights = torch.mean(all_weights, dim=0).numpy()
        
        # ä¿å­˜ç»“æœ
        results['accuracy'].append(accuracy)
        results['cnn_weight'].append(avg_weights[0])
        results['lnn_weight'].append(avg_weights[1])
        
        # æ‰“å°ç»“æœ
        print(f"SNR {snr_db} dB - å‡†ç¡®ç‡: {accuracy:.4f}, æƒé‡ - CNN: {avg_weights[0]:.4f}, LNN: {avg_weights[1]:.4f}")
     
    # ä¿å­˜ç»“æœåˆ°CSV
    import pandas as pd
    pd.DataFrame(results).to_csv(os.path.join(save_dir, 'improved_snr_results.csv'), index=False)
    
    # ç»˜åˆ¶SNRæ€§èƒ½æ›²çº¿
    plt.figure(figsize=(12, 10))
    
    # å‡†ç¡®ç‡æ›²çº¿
    plt.subplot(2, 1, 1)
    plt.plot(snr_range, results['accuracy'], 'o-', markersize=8, linewidth=2)
    plt.axhline(y=0.95, color='r', linestyle='--', linewidth=2, label='95% ç›®æ ‡çº¿')
    plt.xlabel('SNR (dB)')
    plt.ylabel('Accuracy')
    plt.title('Model Performance vs. Signal-to-Noise Ratio')
    plt.grid(True)
    plt.legend()
    plt.ylim(0, 1.05)
    
    # æƒé‡æ›²çº¿
    plt.subplot(2, 1, 2)
    plt.plot(snr_range, results['cnn_weight'], 'o-', label='CNN Weight', linewidth=2)
    plt.plot(snr_range, results['lnn_weight'], 's-', label='LNN Weight', linewidth=2)
    plt.xlabel('SNR (dB)')
    plt.ylabel('Weight')
    plt.title('Model Weights vs. Signal-to-Noise Ratio')
    plt.legend()
    plt.grid(True)
    
    plt.tight_layout()
    plt.savefig(os.path.join(save_dir, 'improved_snr_performance.png'), dpi=300)
    plt.close()
    
    return results


def extract_features_for_visualization(model, dataset, device, max_samples=2000):
    """
    æå–æ¨¡å‹ä¸­é—´å±‚ç‰¹å¾ç”¨äºå¯è§†åŒ–
    """
    model.eval()
    
    # æ³¨å†Œhookæ¥æå–ç‰¹å¾
    features_list = []
    def hook_fn(module, input, output):
        features_list.append(output.detach().cpu())
    
    # åœ¨èåˆå±‚æå–ç‰¹å¾
    hook = model.fused_extractor.register_forward_hook(hook_fn)
    
    # å‡†å¤‡æ•°æ®
    dataloader = DataLoader(dataset, batch_size=64, shuffle=False)
    all_labels = []
    sample_count = 0
    
    with torch.no_grad():
        for batch_x, batch_y in dataloader:
            if sample_count >= max_samples:
                break
                
            batch_x = batch_x.to(device)
            batch_y = batch_y.to(device)
            
            # å‰å‘ä¼ æ’­ä»¥è§¦å‘hook
            _ = model(batch_x)
            
            # æ”¶é›†æ ‡ç­¾
            all_labels.extend(batch_y.cpu().numpy())
            sample_count += len(batch_y)
    
    # ç§»é™¤hook
    hook.remove()
    
    # åˆå¹¶ç‰¹å¾
    if features_list:
        features = torch.cat(features_list, dim=0)[:max_samples]
        labels = np.array(all_labels)[:max_samples]
        return features.numpy(), labels
    else:
        return None, None

def create_individual_identification_plot(model, test_dataset, save_dir, device, 
                                        method='tsne', max_samples=2000):
    """
    åˆ›å»ºä¸ªä½“è¯†åˆ«å¯è§†åŒ–å›¾
    """
    print(f"ğŸ¨ ç”Ÿæˆä¸ªä½“è¯†åˆ«å¯è§†åŒ–å›¾ (æ–¹æ³•: {method.upper()})...")
    
    # æå–ç‰¹å¾
    features, labels = extract_features_for_visualization(model, test_dataset, device, max_samples)
    
    if features is None:
        print("âŒ ç‰¹å¾æå–å¤±è´¥")
        return
    
    print(f"æå–ç‰¹å¾ç»´åº¦: {features.shape}")
    print(f"æ ‡ç­¾æ•°é‡: {len(np.unique(labels))}")
    
    # é™ç»´å¤„ç†
    if method == 'tsne':
        print("æ‰§è¡Œt-SNEé™ç»´...")
        reducer = TSNE(n_components=2, random_state=42, perplexity=min(30, len(features)//4))
        features_2d = reducer.fit_transform(features)
    
    # åˆ›å»ºé¢œè‰²æ˜ å°„
    unique_labels = np.unique(labels)
    n_classes = len(unique_labels)
    
    # ä½¿ç”¨æ›´å¥½çš„é¢œè‰²æ˜ å°„
    if n_classes <= 10:
        colors = plt.cm.tab10(np.linspace(0, 1, n_classes))
    elif n_classes <= 20:
        colors = plt.cm.tab20(np.linspace(0, 1, n_classes))
    else:
        colors = plt.cm.nipy_spectral(np.linspace(0, 1, n_classes))
    
    # åˆ›å»ºå›¾åƒ
    fig, ax = plt.subplots(figsize=(14, 12))
    
    # ä¸ºæ¯ä¸ªç±»åˆ«ç»˜åˆ¶ç‚¹
    for i, label in enumerate(unique_labels):
        mask = labels == label
        ax.scatter(features_2d[mask, 0], features_2d[mask, 1], 
                   c=[colors[i]], label=f'Aircraft {label:03d}', 
                   s=30, alpha=0.7, edgecolors='black', linewidth=0.5)
    
    ax.set_title(f'Individual Aircraft Identification Visualization ({method.upper()})', 
              fontsize=16, fontweight='bold')
    ax.set_xlabel(f'{method.upper()} Component 1', fontsize=12)
    ax.set_ylabel(f'{method.upper()} Component 2', fontsize=12)
    
    # æ·»åŠ colorbar
    sm = plt.cm.ScalarMappable(cmap=plt.cm.nipy_spectral, norm=plt.Normalize(vmin=unique_labels.min(), vmax=unique_labels.max()))
    sm.set_array([])
    cbar = fig.colorbar(sm, ax=ax)
    cbar.set_label('Aircraft ID', rotation=270, labelpad=15)
    plt.tight_layout()
    
    # ä¿å­˜å›¾åƒ
    save_path = os.path.join(save_dir, f'individual_identification_{method}.png')
    plt.savefig(save_path, dpi=300, bbox_inches='tight')
    plt.close()
    
    print(f"âœ… ä¸ªä½“è¯†åˆ«å›¾å·²ä¿å­˜: {save_path}")
    
    return features_2d, labels

def create_confusion_matrix_plot(model, test_dataset, device, save_dir, batch_size=128):
    """
    ç”Ÿæˆå¹¶ä¿å­˜ä¸ªä½“æ ‡ç­¾è¯†åˆ«çš„æ··æ·†çŸ©é˜µï¼ˆå›¾ç‰‡+CSVï¼‰
    """
    print("\nğŸ“Š æ­£åœ¨ç”Ÿæˆæ··æ·†çŸ©é˜µ...")
    model.eval()
    all_preds = []
    all_labels = []
    from torch.utils.data import DataLoader
    loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)
    with torch.no_grad():
        for batch_x, batch_y in loader:
            batch_x = batch_x.to(device)
            batch_y = batch_y.to(device)
            final_logits, _, _ = model(batch_x)
            preds = torch.argmax(final_logits, dim=1)
            all_preds.append(preds.cpu().numpy())
            all_labels.append(batch_y.cpu().numpy())
    all_preds = np.concatenate(all_preds)
    all_labels = np.concatenate(all_labels)
    # è®¡ç®—æ··æ·†çŸ©é˜µ
    cm = confusion_matrix(all_labels, all_preds)
    # ä¿å­˜ä¸ºCSV
    cm_csv_path = os.path.join(save_dir, 'confusion_matrix.csv')
    pd.DataFrame(cm).to_csv(cm_csv_path, index=True, header=True)
    print(f"æ··æ·†çŸ©é˜µCSVå·²ä¿å­˜: {cm_csv_path}")
    # ç»˜åˆ¶çƒ­åŠ›å›¾
    plt.figure(figsize=(min(20, 0.5*cm.shape[0]), min(20, 0.5*cm.shape[1])))
    sns.heatmap(cm, annot=False, fmt='d', cmap='Blues', cbar=True)
    plt.title('Individual Identification Confusion Matrix', fontsize=16)
    plt.xlabel('Predicted Label')
    plt.ylabel('True Label')
    plt.tight_layout()
    cm_img_path = os.path.join(save_dir, 'confusion_matrix.png')
    plt.savefig(cm_img_path, dpi=300)
    plt.close()
    print(f"æ··æ·†çŸ©é˜µå›¾ç‰‡å·²ä¿å­˜: {cm_img_path}")
    return cm

def create_all_visualizations(model, test_dataset, device, save_dir):
    """
    åˆ›å»ºæ‰€æœ‰å¯è§†åŒ–å›¾è¡¨
    """
    print("\nğŸ¨ å¼€å§‹ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨...")
    # åˆ›å»ºä¿å­˜ç›®å½•
    os.makedirs(save_dir, exist_ok=True)
    # 1. t-SNEå¯è§†åŒ–
    create_individual_identification_plot(
        model, test_dataset, save_dir, device, method='tsne'
    )
    # 2. æ··æ·†çŸ©é˜µ
    create_confusion_matrix_plot(model, test_dataset, device, save_dir)
    print("å¯è§†åŒ–å›¾è¡¨ç”Ÿæˆå®Œæˆï¼")

def main(data_path, batch_size=32, save_dir='./improved_results', subset_ratio=0.5, 
         snr_high=0.90, snr_mid=0.09, snr_low=0.01, min_snr=-10, max_snr=20, 
         finetune_epochs=15, num_epochs=30):
    import os
    import numpy as np
    import pandas as pd
    import matplotlib.pyplot as plt

    # åˆ›å»ºç»“æœç›®å½•
    os.makedirs(save_dir, exist_ok=True)
    finetune_save_dir = os.path.join(save_dir, 'finetune_high_snr')
    os.makedirs(finetune_save_dir, exist_ok=True)

    # åŠ è½½å’Œé¢„å¤„ç†æ•°æ®
    print(f"åŠ è½½åˆ†ç»„æ•°æ®: {data_path}")
    train_dataset, val_dataset, test_dataset, num_classes, label_map, scaler = load_and_preprocess_grouped_data(data_path)
    print(f"ç±»åˆ«æ•°é‡: {num_classes}")

    # åˆ›å»ºæ¨¡å‹ - input_dimä¿®æ”¹ä¸º30 (15ç¬æ€ + 15ç¨³æ€)
    model = ImprovedEnsembleADSBNetwork(
        input_dim=30,  # ä¿®æ”¹ä¸º30ç»´è¾“å…¥
        num_classes=num_classes,
        hidden_dim=128
    )

    # è®­ç»ƒæ¨¡å‹
    finetune_lr = 0.0002
    model, _ = train_improved_ensemble(
        model=model,
        train_dataset=train_dataset,
        val_dataset=val_dataset,
        num_epochs=num_epochs,
        batch_size=256,
        subset_ratio=1.0,
        change_epochs=2,
        noise_prob=0.3,
        min_snr=-10,
        max_snr=20,
        lr=finetune_lr,
        save_dir=finetune_save_dir,
        snr_high=0.9,
        snr_mid=0.05,
        snr_low=0.05
    )

    # åŠ è½½æœ€ä½³æ¨¡å‹
    model.load_state_dict(torch.load(os.path.join(finetune_save_dir, 'best_improved_model.pth')))

    # æµ‹è¯•æ¨¡å‹åœ¨ä¸åŒSNRä¸‹çš„è¡¨ç°
    print("\n====== æ¨¡å‹åœ¨ä¸åŒSNRä¸‹çš„è¡¨ç° ======")
    snr_range = [20, 15, 10, 5, 0, -5, -10]
    results = {'SNR (dB)': [], 'Accuracy': []}
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    model = model.to(device)

    create_all_visualizations(model, test_dataset, device, save_dir)
    model.eval()
    
    for snr_db in snr_range:
        correct = 0
        total = 0
        test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)
        with torch.no_grad():
            for batch_x, batch_y in test_loader:
                batch_x, _ = add_advanced_noise_to_batch(batch_x, min_snr=snr_db, max_snr=snr_db)
                batch_x = batch_x.to(device)
                batch_y = batch_y.to(device)
                final_logits, _, _ = model(batch_x)
                _, predicted = torch.max(final_logits, 1)
                total += batch_y.size(0)
                correct += (predicted == batch_y).sum().item()
        acc = correct / total
        results['SNR (dB)'].append(snr_db)
        results['Accuracy'].append(acc)
        print(f"SNR {snr_db} dB - Accuracy: {acc:.4f}")

    # ä¿å­˜ç»“æœ
    pd.DataFrame(results).to_csv(os.path.join(finetune_save_dir, 'final_snr_performance.csv'), index=False)

    # ç»˜åˆ¶å‡†ç¡®ç‡-SNRæ›²çº¿
    plt.figure(figsize=(7,5))
    plt.plot(results['SNR (dB)'], results['Accuracy'], 'o-', linewidth=2)
    plt.xlabel('SNR (dB)')
    plt.ylabel('Accuracy')
    plt.title('Model Accuracy vs SNR (Grouped Features)')
    plt.grid(True)
    plt.ylim(0, 1.05)
    plt.tight_layout()
    plt.savefig(os.path.join(finetune_save_dir, 'final_snr_performance.png'), dpi=300)
    plt.close()
    print(f"ç»“æœå·²ä¿å­˜åˆ°: {finetune_save_dir}")

# å¦‚æœä½œä¸ºè„šæœ¬æ‰§è¡Œï¼Œè¿è¡Œä¸»å‡½æ•°
if __name__ == "__main__":
    import argparse
    
    parser = argparse.ArgumentParser(description="è®­ç»ƒæ”¹è¿›çš„ADS-Bä¿¡å·è¯†åˆ«é›†æˆæ¨¡å‹(åˆ†ç»„ç‰¹å¾ç‰ˆæœ¬)")
    parser.add_argument('--data', type=str, required=True, help='åˆ†ç»„é™ç»´åçš„æ•°æ®æ–‡ä»¶è·¯å¾„')
    parser.add_argument('--batch_size', type=int, default=64, help='æ‰¹æ¬¡å¤§å°')
    parser.add_argument('--save_dir', type=str, default='./improved_results', help='ä¿å­˜ç»“æœçš„ç›®å½•')
    parser.add_argument('--subset_ratio', type=float, default=0.5, help='è®­ç»ƒé›†é‡‡æ ·æ¯”ä¾‹ï¼Œ0~1ä¹‹é—´')
    parser.add_argument('--snr_high', type=float, default=0.90, help='æé«˜SNRé‡‡æ ·æƒé‡(15~20dB)')
    parser.add_argument('--snr_mid', type=float, default=0.09, help='é«˜SNRé‡‡æ ·æƒé‡(5~15dB)')
    parser.add_argument('--snr_low', type=float, default=0.01, help='ä½/ä¸­SNRé‡‡æ ·æƒé‡(-10~5dB)')
    parser.add_argument('--min_snr', type=int, default=-10, help='æœ€å°SNR(dB)')
    parser.add_argument('--max_snr', type=int, default=20, help='æœ€å¤§SNR(dB)')
    parser.add_argument('--finetune_epochs', type=int, default=15, help='Fine-tuneé˜¶æ®µçš„è®­ç»ƒè½®æ•°')
    parser.add_argument('--epochs', type=int, default=30, help='è®­ç»ƒæ€»è½®æ•°')
    
    args = parser.parse_args()
    
    # è¿è¡Œä¸»å‡½æ•°
    main(args.data, args.batch_size, args.save_dir, args.subset_ratio, 
         args.snr_high, args.snr_mid, args.snr_low, args.min_snr, args.max_snr, 
         args.finetune_epochs, args.epochs)